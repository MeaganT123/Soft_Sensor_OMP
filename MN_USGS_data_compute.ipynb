{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "161ccdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import functions and libraries from scripts\n",
    "from GP_funcs import *\n",
    "from file_opening import *\n",
    "from SCB_conversion import SCB_CONVERSION\n",
    "\n",
    "#for plotting\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab7e671",
   "metadata": {},
   "source": [
    "# Load USGS site data nd calculate SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3a0ef5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,) (20,)\n",
      "(22,) (22,)\n",
      "(21,) (21,)\n",
      "(19,) (19,)\n"
     ]
    }
   ],
   "source": [
    "#load USGS data\n",
    "USGS_site_id = ['05325000','05325300','05330000','05331000']\n",
    "ADVM_readings = create_USGS_dfs('ADVM', USGS_site_id) #Sensor readings for all sites\n",
    "Grab_samples = create_USGS_dfs('SSC_Q', USGS_site_id) #Grab samples and flow for all sites\n",
    "Qall_time = create_USGS_dfs('Qall', USGS_site_id) #Discharge for total time range of sensor deployment per site\n",
    "\n",
    "dfc = pd.read_csv(r'USGS_data/USGS_site_consts.csv') # Read in constants for all sites\n",
    "dfc['Site_ID'] = dfc['Site_ID'].map(toName) #Converts Site_ID to string type\n",
    "\n",
    "data_dictionary = {} # empty dictionary to put dataframes into, keys are site id\n",
    "\n",
    "for id in USGS_site_id:\n",
    "    #Selects constants for each USGS site\n",
    "    Consts = dfc.loc[dfc['Site_ID'] ==  id].iloc[0, 1:]\n",
    "\n",
    "    data_dictionary[id] = { 'ADVM' : ADVM_readings[id],\n",
    "                            'Samples' : Grab_samples[id],\n",
    "                            'Flow' : Qall_time[id],\n",
    "                            'Consts' : Consts # This is a pandas series\n",
    "                        }\n",
    "\n",
    "    ## add in calculated parameters from raw data\n",
    "    site_data = data_dictionary[id]\n",
    "    \n",
    "    # Calculate derivative of flow\n",
    "    Qsamp = site_data['Samples']['Q']\n",
    "    Tsamp = site_data['Samples']['DateTime']\n",
    "    DTsamp = pd.Series(serialTimeToDatetime(Tsamp, tz_hour_offset = -5))\n",
    "\n",
    "    site_data['Samples']['dQdT'] = (Qsamp.diff() / DTsamp.diff().dt.total_seconds())\n",
    "    print(Qsamp.shape, site_data['Samples']['dQdT'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38ece9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05325000 Avg\n",
      "(10, 1) R_invalid, (10,)\n",
      "05325300 Avg\n",
      "(10, 1) R_invalid, (10,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gm/ycf4j6kn1bqf6206rvg8458h0000gn/T/ipykernel_41852/3504572476.py:49: RuntimeWarning: invalid value encountered in log10\n",
      "  lSAC = np.log10(SAC)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05330000 Avg\n",
      "(10, 1) R_invalid, (10,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gm/ycf4j6kn1bqf6206rvg8458h0000gn/T/ipykernel_41852/3504572476.py:49: RuntimeWarning: invalid value encountered in log10\n",
      "  lSAC = np.log10(SAC)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05331000 1\n",
      "(5, 1) R_invalid, (5,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "''' vvvvvvvvvvvvvvvvvvvvvv Loop that prepares and runs site data to calculate SCB, SAC vvvvvvvvvvvvvvvvvvvvvv '''\n",
    "for id in USGS_site_id :\n",
    "    site_data = data_dictionary[id]\n",
    "    Constsa = site_data['Consts'].to_numpy()\n",
    "    beams = Constsa[7]\n",
    "\n",
    "    print(id, Constsa[7])\n",
    "\n",
    "    #a is start cell, b is end cell for data reading\n",
    "    a = '01'\n",
    "    b = '%02d' % site_data['Consts'][6] #will give end cell number and add appropriate 0 if single digit int\n",
    "\n",
    "    #Import sensor readings for site site_num and store as arrays\n",
    "    #selects dataframe with matching key (USGS_site_id number) from ADVM_readings library\n",
    "    df_a = site_data['ADVM']\n",
    "    date_time = df_a['DateTime'].to_numpy()\n",
    "    Temp = df_a['ADVMTemp'].to_numpy()\n",
    "    Vbeam = df_a['Vbeam'].to_numpy()\n",
    "    # If 2 beams being used, then make list of matrix of SNR and AMP\n",
    "    if beams == 'Avg':\n",
    "        SNR = [beam_array(df_a, ['Cell'+a+'SNR1','Cell'+b+'SNR1']), beam_array(df_a, ['Cell'+a+'SNR2','Cell'+b+'SNR2'])]\n",
    "        AMP = [beam_array(df_a, ['Cell'+a+'Amp1','Cell'+b+'Amp1']), beam_array(df_a, ['Cell'+a+'Amp2','Cell'+b+'Amp2'])]\n",
    "    # Else just have 2 matrices\n",
    "    #idk why site 3 only uses beam 1 since the csv has them all?? maybe beam 2 wasn't good\n",
    "    elif beams == '1':\n",
    "        SNR = beam_array(df_a, ['Cell'+a+'SNR1','Cell'+b+'SNR1'])\n",
    "        AMP = beam_array(df_a, ['Cell'+a+'Amp1','Cell'+b+'Amp1'])\n",
    "    elif beams == '2':\n",
    "        SNR = beam_array(df_a, ['Cell'+a+'SNR2','Cell'+b+'SNR2'])\n",
    "        AMP = beam_array(df_a, ['Cell'+a+'Amp2','Cell'+b+'Amp2'])\n",
    "\n",
    "\n",
    "    #Import measured SSC values and flow from the USGS site site_num and store as arrays\n",
    "    df_s = site_data['Samples']\n",
    "    date_time2 = df_s['DateTime'].to_numpy()\n",
    "    SSC = df_s['SSC'].to_numpy()\n",
    "\n",
    "   \n",
    "    #Calculate mean SCB and SAC from sensor geometry and data\n",
    "    Mean_SCB, SAC = SCB_CONVERSION(SNR, AMP, Constsa, Vbeam, Temp, date_time).convert_SNR_to_Mean_SCB()\n",
    "\n",
    "    # matching measured SSC values from the USGS site and backscatter data to it by choosing closest times\n",
    "    ind_match = [(np.abs(date_time - date_time2[i])).argmin() for i in range(len(date_time2))]\n",
    "    SAC_matched = SAC[ind_match]\n",
    "    Mean_SCB_matched = Mean_SCB[ind_match]\n",
    "    \n",
    "\n",
    "    #change to log10 options\n",
    "    lSAC = np.log10(SAC)\n",
    "    lSAC_matched = np.log10(SAC_matched)\n",
    "    lSCB = np.log10(Mean_SCB)\n",
    "    lSCB_matched = np.log10(Mean_SCB_matched)\n",
    "    lSSC = np.log10(SSC)\n",
    "    \n",
    "    #store arrays back into dataframes\n",
    "\n",
    "    # put time series of SAC and SCB into ADVM dataframe\n",
    "    data_matrix = np.vstack([SAC, Mean_SCB, lSAC, lSCB]).transpose()\n",
    "    df = pd.DataFrame(data_matrix, columns=['SAC','SCB', 'logSAC','logSCB'])\n",
    "    site_data['ADVM'] = pd.concat([df_a, df], axis = 1)\n",
    "\n",
    "    # Update matched output values to Samples dataframe\n",
    "    matched_data_matrix = np.vstack([SAC_matched, Mean_SCB_matched, lSSC, lSAC_matched, lSCB_matched]).transpose()\n",
    "    matched_df = pd.DataFrame(matched_data_matrix, columns=['SAC', 'SCB','logSSC','logSAC', 'logSCB'])\n",
    "    site_data['Samples'] = pd.concat([df_s, matched_df], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b08fce46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For saving computed SAC and stuff values into csv \n",
    "id = 3\n",
    "site_data = data_dictionary[USGS_site_id[id]]\n",
    "# site_data['Samples']['SAC'].to_numpy()\n",
    "# print(site_data['Samples']['SAC'], seeya['Samples']['SAC'])\n",
    "\n",
    "# site_data['Samples']\n",
    "site_data.keys()\n",
    "site_data['Samples']\n",
    "\n",
    "site_data['Samples'].to_csv(f'{str(USGS_site_id[id])}_samples.csv', index=False)\n",
    "site_data['ADVM'].to_csv(f'{str(USGS_site_id[id])}_sensor.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70afbd24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adap_samp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
